{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "nbpresent": {
     "id": "6a63605e-0508-479a-94d0-edc7195a51a2"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "from tqdm.auto import tqdm as tq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import albumentations as alb\n",
    "\n",
    "PATH = '../input/pku-autonomous-driving/'\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0024d699-064c-4fb3-a3c2-04bb8c3c65ea"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "nbpresent": {
     "id": "63ca552d-09e4-4632-bda9-20e51805d3ee"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "test = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "\n",
    "# From camera.zip\n",
    "camera_matrix = np.array([[2304.5479, 0,  1686.2379],\n",
    "                          [0, 2305.8757, 1354.9849],\n",
    "                          [0, 0, 1]], dtype=np.float32)\n",
    "camera_matrix_inv = np.linalg.inv(camera_matrix)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "10342326-4cfb-48ed-9384-ad869c9cecba"
    }
   },
   "outputs": [],
   "source": [
    "corrupted_arr = [\"ID_1a5a10365\",\"ID_4d238ae90\",\"ID_408f58e9f\",\"ID_bb1d991f6\",\"ID_c44983aeb\"]\n",
    "for _id in corrupted_arr:\n",
    "    #plt.imshow( cv2.imread(PATH + 'train_images/' + _id + '.jpg')[:,:,::-1] )\n",
    "    #plt.show()\n",
    "    pass\n",
    "print(\"before\", len(train))\n",
    "drop_train = train.set_index(\"ImageId\").drop( index=corrupted_arr )\n",
    "train = drop_train.reset_index()\n",
    "print(\"after\", len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d8c2e9a8-b854-473b-86d4-3fd31c7dfbd9"
    }
   },
   "source": [
    "**ImageId** column contains names of images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for simple run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_RUN_TEST = False\n",
    "if SIMPLE_RUN_TEST:\n",
    "    train = train[:20]\n",
    "    test  = test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "7d9e8309-c6ff-4791-93e0-ec9a3acf83a9"
    }
   },
   "outputs": [],
   "source": [
    "def imread(path, fast_mode=False):\n",
    "    img = cv2.imread(path)\n",
    "    if not fast_mode and img is not None and len(img.shape) == 3:\n",
    "        img = np.array(img[:, :, ::-1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(PATH + 'train_images/ID_8a6e65317' + '.jpg')\n",
    "IMG_SHAPE = img.shape\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "899ba2fa-a9a6-4b4a-b3d8-8a1fb11d037b"
    }
   },
   "outputs": [],
   "source": [
    "def str2coords(s, names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']):\n",
    "    '''\n",
    "    Input:\n",
    "        s: PredictionString (e.g. from train dataframe)\n",
    "        names: array of what to extract from the string\n",
    "    Output:\n",
    "        list of dicts with keys from `names`\n",
    "    '''\n",
    "    coords = []\n",
    "    for l in np.array(s.split()).reshape([-1, 7]):\n",
    "        coords.append(dict(zip(names, l.astype('float'))))\n",
    "        if 'id' in coords[-1]:\n",
    "            coords[-1]['id'] = int(coords[-1]['id'])\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "0a1a919f-a172-407e-b2d3-857a072bf5d7"
    }
   },
   "outputs": [],
   "source": [
    "inp = train['PredictionString'][0]\n",
    "print('Example input:\\n', inp)\n",
    "print()\n",
    "print('Output:\\n', str2coords(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5a6f93fb-2b54-4cc5-9eb1-e008642de2ce"
    }
   },
   "source": [
    "# Data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "983b9fa5-73c9-4ab5-a32c-2e9cc1612a1b"
    }
   },
   "outputs": [],
   "source": [
    "lens = [len(str2coords(s)) for s in train['PredictionString']]\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.countplot(lens);\n",
    "plt.xlabel('Number of cars in image');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "9f5d85ac-3beb-4c25-a12d-6ea59838249c"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.distplot(reduce(lambda a, b: a + b, [[c['x'] for c in str2coords(s)] for s in train['PredictionString']]), bins=500);\n",
    "#sns.distplot([str2coords(s)[0]['x'] for s in train['PredictionString']]);\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "0bd30b4c-2de6-4072-bd67-f769c23de896"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.distplot(reduce(lambda a, b: a + b, [[c['y'] for c in str2coords(s)] for s in train['PredictionString']]), bins=500);\n",
    "plt.xlabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "0a8699a5-f77f-4c29-bc5a-ffd211fe9265"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.distplot(reduce(lambda a, b: a + b, [[c['z'] for c in str2coords(s)] for s in train['PredictionString']]), bins=1500);\n",
    "plt.xlabel('z')\n",
    "plt.xlim(0,500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "4628c757-e078-4838-9e65-cee895f54ed2"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.distplot(reduce(lambda a, b: a + b, [[c['yaw'] for c in str2coords(s)] for s in train['PredictionString']]));\n",
    "plt.xlabel('yaw')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "633be6aa-212e-48fb-8ad7-f27c03ea31f6"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.distplot(reduce(lambda a, b: a + b, [[c['pitch'] for c in str2coords(s)] for s in train['PredictionString']]));\n",
    "plt.xlabel('pitch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "09b53838-67cf-4769-80b7-a57bc702ae5d"
    }
   },
   "source": [
    "I guess, pitch and yaw are mixed up in this dataset. Pitch cannot be that big. That would mean that cars are upside down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "ee8e7910-d108-4b08-b907-047f0eb2fbd9"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.distplot(reduce(lambda a, b: a + b, [[c['roll'] for c in str2coords(s)] for s in train['PredictionString']]));\n",
    "plt.xlabel('roll')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(x, angle):\n",
    "    x = x + angle\n",
    "    x = x - (x + np.pi) // (2 * np.pi) * 2 * np.pi\n",
    "    return x\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.distplot(reduce(lambda a, b: a + b, [[rotate(c['roll'], np.pi) for c in str2coords(s)] for s in train['PredictionString']]));\n",
    "plt.xlabel('roll rotated by pi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "63a68ff2-3fd7-4c58-aa77-c97b5a309926"
    }
   },
   "source": [
    "# 2D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "64874f90-1066-4d31-91a8-76d74e9024ac"
    }
   },
   "outputs": [],
   "source": [
    "def get_img_coords(s):\n",
    "    '''\n",
    "    Input is a PredictionString (e.g. from train dataframe)\n",
    "    Output is two arrays:\n",
    "        xs: x coordinates in the image\n",
    "        ys: y coordinates in the image\n",
    "    '''\n",
    "    coords = str2coords(s)\n",
    "    xs = [c['x'] for c in coords]\n",
    "    ys = [c['y'] for c in coords]\n",
    "    zs = [c['z'] for c in coords]\n",
    "    P = np.array(list(zip(xs, ys, zs))).T\n",
    "    img_p = np.dot(camera_matrix, P).T\n",
    "    img_p[:, 0] /= img_p[:, 2]\n",
    "    img_p[:, 1] /= img_p[:, 2]\n",
    "    img_xs = img_p[:, 0]\n",
    "    img_ys = img_p[:, 1]\n",
    "    img_zs = img_p[:, 2] # z = Distance from the camera\n",
    "    return img_xs, img_ys\n",
    "\n",
    "if not SIMPLE_RUN_TEST:\n",
    "    plt.figure(figsize=(14,14))\n",
    "    plt.imshow(imread(PATH + 'train_images/' + train['ImageId'][2217] + '.jpg'))\n",
    "    plt.scatter(*get_img_coords(train['PredictionString'][2217]), color='red', s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "50adda48-568f-4f5c-a88c-135dd6b6a500"
    }
   },
   "source": [
    "One point is out of image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b8c97c09-b206-4099-9820-cc100ee32477"
    }
   },
   "source": [
    "Let's look at the distribution of all points. Image is here just for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "5f18bcda-74c7-4e7e-b2ba-768dfe173040"
    }
   },
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for ps in train['PredictionString']:\n",
    "    x, y = get_img_coords(ps)\n",
    "    xs += list(x)\n",
    "    ys += list(y)\n",
    "\n",
    "if not SIMPLE_RUN_TEST:\n",
    "    plt.figure(figsize=(18,18))\n",
    "    plt.imshow(imread(PATH + 'train_images/' + train['ImageId'][2217] + '.jpg'), alpha=0.3)\n",
    "    plt.scatter(xs, ys, color='red', s=10, alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d483302e-8dbb-4797-9286-21bf53d9091e"
    }
   },
   "source": [
    "Many points are outside!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bfee4d93-b435-4589-a0c5-0935245ebf7b"
    }
   },
   "source": [
    "Let's look at this distribution \"from the sky\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "6bdce59a-7762-4859-80b7-2f94b350c680"
    }
   },
   "outputs": [],
   "source": [
    "# Cars points\n",
    "xs, ys = [], []\n",
    "for ps in train['PredictionString']:\n",
    "    coords = str2coords(ps)\n",
    "    xs += [c['x'] for c in coords]\n",
    "    ys += [c['y'] for c in coords]\n",
    "\n",
    "# Road points\n",
    "road_width = 6\n",
    "road_xs = [-road_width, road_width, road_width, -road_width, -road_width]\n",
    "road_ys = [0, 0, 500, 500, 0]\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.axes().set_aspect(1)\n",
    "# View road\n",
    "plt.fill(road_xs, road_ys, alpha=0.2, color='gray')\n",
    "plt.plot([road_width/2,road_width/2], [0,500], alpha=0.4, linewidth=4, color='white', ls='--')\n",
    "plt.plot([-road_width/2,-road_width/2], [0,500], alpha=0.4, linewidth=4, color='white', ls='--')\n",
    "# View cars\n",
    "plt.scatter(xs, ys, color='red', s=20, alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e97fb348-4bf4-4459-ab4c-3cbbabeebcbe"
    }
   },
   "source": [
    "Some points are very far away\n",
    "\n",
    "Scale up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "03eebe67-7a93-4b74-ad46-50306b9b221d"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.axes().set_aspect(1)\n",
    "plt.xlim(-50,50)\n",
    "plt.ylim(0,50)\n",
    "\n",
    "# View road\n",
    "plt.fill(road_xs, road_ys, alpha=0.2, color='gray')\n",
    "plt.plot([road_width/2,road_width/2], [0,100], alpha=0.4, linewidth=4, color='white', ls='--')\n",
    "plt.plot([-road_width/2,-road_width/2], [0,100], alpha=0.4, linewidth=4, color='white', ls='--')\n",
    "# View cars\n",
    "plt.scatter(xs, ys, color='red', s=10, alpha=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c3ed48e9-2bea-479e-8e38-f8743b00c6ec"
    }
   },
   "source": [
    "# 3D Visualization\n",
    "Used code from https://www.kaggle.com/zstusnoopy/visualize-the-location-and-3d-bounding-box-of-car, but made it one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "0620bdfe-a8cc-4f28-a488-faf81a748072"
    }
   },
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "\n",
    "# convert euler angle to rotation matrix\n",
    "def euler_to_Rot(yaw, pitch, roll):\n",
    "    Y = np.array([[cos(yaw), 0, sin(yaw)],\n",
    "                  [0, 1, 0],\n",
    "                  [-sin(yaw), 0, cos(yaw)]])\n",
    "    P = np.array([[1, 0, 0],\n",
    "                  [0, cos(pitch), -sin(pitch)],\n",
    "                  [0, sin(pitch), cos(pitch)]])\n",
    "    R = np.array([[cos(roll), -sin(roll), 0],\n",
    "                  [sin(roll), cos(roll), 0],\n",
    "                  [0, 0, 1]])\n",
    "    return np.dot(Y, np.dot(P, R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "4b22780a-18c3-4d1e-92e2-57f0f41c385e"
    }
   },
   "outputs": [],
   "source": [
    "def draw_line(image, points):\n",
    "    color = (255, 0, 0)\n",
    "    cv2.line(image, tuple(points[0][:2]), tuple(points[3][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[0][:2]), tuple(points[1][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[1][:2]), tuple(points[2][:2]), color, 16)\n",
    "    cv2.line(image, tuple(points[2][:2]), tuple(points[3][:2]), color, 16)\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_points(image, points):\n",
    "    for (p_x, p_y, p_z) in points:\n",
    "        cv2.circle(image, (p_x, p_y), int(1000 / p_z), (0, 255, 0), -1)\n",
    "#         if p_x > image.shape[1] or p_y > image.shape[0]:\n",
    "#             print('Point', p_x, p_y, 'is out of image with shape', image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "0bf0b717-12ce-42fa-855b-eb00090d9571"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(img, coords):\n",
    "    # You will also need functions from the previous cells\n",
    "    x_l = 1.02\n",
    "    y_l = 0.80\n",
    "    z_l = 2.31\n",
    "    \n",
    "    img = img.copy()\n",
    "    for point in coords:\n",
    "        # Get values\n",
    "        x, y, z = point['x'], point['y'], point['z']\n",
    "        yaw, pitch, roll = -point['pitch'], -point['yaw'], -point['roll']\n",
    "        # Math\n",
    "        Rt = np.eye(4)\n",
    "        t = np.array([x, y, z])\n",
    "        Rt[:3, 3] = t\n",
    "        Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n",
    "        Rt = Rt[:3, :]\n",
    "        P = np.array([[x_l, -y_l, -z_l, 1],\n",
    "                      [x_l, -y_l, z_l, 1],\n",
    "                      [-x_l, -y_l, z_l, 1],\n",
    "                      [-x_l, -y_l, -z_l, 1],\n",
    "                      [0, 0, 0, 1]]).T\n",
    "        img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n",
    "        img_cor_points = img_cor_points.T\n",
    "        img_cor_points[:, 0] /= img_cor_points[:, 2]\n",
    "        img_cor_points[:, 1] /= img_cor_points[:, 2]\n",
    "        img_cor_points = img_cor_points.astype(int)\n",
    "        # Drawing\n",
    "        img = draw_line(img, img_cor_points)\n",
    "        img = draw_points(img, img_cor_points[-1:])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "5fc17989-3a9f-4a6d-885c-fa47b9da8c87"
    }
   },
   "outputs": [],
   "source": [
    "n_rows = 6\n",
    "\n",
    "for idx in range(n_rows):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20,20))\n",
    "    img = imread(PATH + 'train_images/' + train['ImageId'].iloc[idx] + '.jpg')\n",
    "    axes[0].imshow(img)\n",
    "    img_vis = visualize(img, str2coords(train['PredictionString'].iloc[idx]))\n",
    "    axes[1].imshow(img_vis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "74e48e14-f78b-4691-8071-65400e02806f"
    }
   },
   "outputs": [],
   "source": [
    "### CHECK ORIENTATION\n",
    "### Pitchは前向きが0. 空から見てひだりまわりが正\n",
    "n_rows = 1\n",
    "idx = 7\n",
    "if False:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    img = imread(PATH + 'train_images/' + train['ImageId'].iloc[idx] + '.jpg')\n",
    "    COR_IDX = 2\n",
    "    cor = str2coords(train['PredictionString'].iloc[idx])[COR_IDX]\n",
    "    print(\"\", cor)\n",
    "    img_vis = visualize(img, [ cor ]  )\n",
    "    plt.imshow(img_vis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6f1121d8-0353-453f-8a99-b1230811b173"
    }
   },
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "04405c31-3249-40d8-963c-0a1006947fbb"
    }
   },
   "outputs": [],
   "source": [
    "ORIG_W = 3384\n",
    "ORIG_H = 2710\n",
    "# train image size\n",
    "\n",
    "if True:  # ORIGINAL-SIZE\n",
    "    IMG_WIDTH = 2048\n",
    "    IMG_HEIGHT = 512  #IMG_WIDTH // 4\n",
    "    MARGIN_W = ORIG_W // 4  # 846\n",
    "else:  #this was bad\n",
    "    IMG_WIDTH = 512*3  # 512*4==2048\n",
    "    IMG_HEIGHT = 512\n",
    "    MARGIN_W = ORIG_W//4\n",
    "\n",
    "MODEL_SCALE = 8  # mask shrink rate\n",
    "\n",
    "FX, FY = 2304.5479,  2305.8757\n",
    "CX, CY = 1686.2379, 1354.9849\n",
    "def XYZ2UV(x,y,z):\n",
    "    u = FX * x / z + CX\n",
    "    v = FY * y / z + CY\n",
    "    return u,v\n",
    "def UVZ2XY(u,v,z):\n",
    "    x = z * (u - CX) / FX\n",
    "    y = z * (v - CY) / FY\n",
    "    return x,y\n",
    "\n",
    "# OLD CODE #\n",
    "#x, y = y, x\n",
    "#x = (x - img.shape[0] // 2) * IMG_HEIGHT / (img.shape[0] // 2) / MODEL_SCALE\n",
    "#x = np.round(x).astype('int')\n",
    "#y = (y + img.shape[1] // 4) * IMG_WIDTH / (img.shape[1] * 1.5) / MODEL_SCALE\n",
    "#y = np.round(y).astype('int')\n",
    "def VU2maskVU(v,u):  # V:vertical, U:horizontal\n",
    "    mask_V = (v - ORIG_H // 2) * IMG_HEIGHT / (ORIG_H // 2) / MODEL_SCALE\n",
    "    mask_U = (u + MARGIN_W) * IMG_WIDTH  / (ORIG_W + 2*MARGIN_W) / MODEL_SCALE\n",
    "    return mask_V, mask_U\n",
    "def maskVU2VU(mask_v_float, mask_u_float):\n",
    "    v = ORIG_H // 2 + mask_v_float * MODEL_SCALE / IMG_HEIGHT * (ORIG_H // 2)\n",
    "    u = mask_u_float * MODEL_SCALE * (ORIG_W + 2*MARGIN_W) / IMG_WIDTH - MARGIN_W\n",
    "    return v, u\n",
    "## test code\n",
    "#_v, _u = 2709, 1611\n",
    "#_mv, _mu = VU2maskVU(_v, _u)\n",
    "#print(\"v,u :\", _v, _u)\n",
    "#print(\"mask v,u :\", _mv, _mu)\n",
    "#print(\"v,u (backed) :\", maskVU2VU( _mv, _mu ) )\n",
    "\n",
    "## assertion usage\n",
    "#REGR_TARGETS = sorted( [\"x\",\"y\",\"z\", \"yaw\",\"pitch_sin\", \"pitch_cos\", \"roll\"] )\n",
    "REGR_TARGETS = sorted( [\"vdiff\",\"udiff\",\"z\", \"yaw\",\"pitch_sin\", \"pitch_cos\", \"roll\"] )\n",
    "def _regr_preprocess(regr_dict, vdiff, udiff):\n",
    "    \"\"\" vdiff(h orientation), udiff is regression target \"\"\"\n",
    "    regr_dict[\"vdiff\"] = vdiff\n",
    "    regr_dict[\"udiff\"] = udiff\n",
    "\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], np.pi)\n",
    "    # Pitch\n",
    "    if False:  # regress pitch from car(camera)\n",
    "        pitch_from_car = regr_dict['pitch'] + np.arctan(regr_dict['x'] / regr_dict['z']) # calc in radian\n",
    "        regr_dict['pitch_sin'] = sin(pitch_from_car)\n",
    "        regr_dict['pitch_cos'] = cos(pitch_from_car)\n",
    "    else:  # regress world-pitch directly\n",
    "        regr_dict['pitch_sin'] = sin(regr_dict['pitch'])\n",
    "        regr_dict['pitch_cos'] = cos(regr_dict['pitch'])\n",
    "\n",
    "    # Regress log(Z)\n",
    "    regr_dict[\"z\"] = np.log(regr_dict[\"z\"])\n",
    "    \n",
    "    regr_dict.pop('x')\n",
    "    regr_dict.pop('y')\n",
    "    regr_dict.pop('pitch')\n",
    "    regr_dict.pop('id')\n",
    "    return regr_dict\n",
    "\n",
    "def _regr_back(regr_dict, mask_V_pos, mask_U_pos):\n",
    "    # back log(z) to z\n",
    "    regr_dict[\"z\"] = np.exp(regr_dict[\"z\"])\n",
    "\n",
    "    _v, _u = maskVU2VU( mask_V_pos + regr_dict[\"vdiff\"], mask_U_pos + regr_dict[\"udiff\"] )\n",
    "    regr_dict[\"x\"], regr_dict[\"y\"] = UVZ2XY(_u, _v, regr_dict[\"z\"])\n",
    "\n",
    "    regr_dict['roll'] = rotate(regr_dict['roll'], -np.pi)\n",
    "\n",
    "    ## Pitch\n",
    "    pitch_sin = regr_dict['pitch_sin'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    pitch_cos = regr_dict['pitch_cos'] / np.sqrt(regr_dict['pitch_sin']**2 + regr_dict['pitch_cos']**2)\n",
    "    if False:\n",
    "        # pitch from camera\n",
    "        pitch_from_car = np.arccos(pitch_cos) * np.sign(pitch_sin)\n",
    "        # back to real-workd pitch\n",
    "        regr_dict['pitch'] = pitch_from_car - np.arctan(regr_dict[\"x\"] / regr_dict[\"z\"])\n",
    "    else:\n",
    "        regr_dict['pitch'] = np.arccos(pitch_cos) * np.sign(pitch_sin)\n",
    "    \n",
    "    return regr_dict\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = img[img.shape[0] // 2:]\n",
    "    bg = np.ones_like(img) * img.mean(1, keepdims=True).astype(img.dtype)\n",
    "    bg = bg[:, :MARGIN_W]\n",
    "    img = np.concatenate([bg, img, bg], 1)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    return (img / 255).astype('float32')\n",
    "def preprocess_mask_image(img):  # 上関数とといっしょに編集するように注意\n",
    "    img = img[img.shape[0] // 2:]\n",
    "    bg = np.zeros_like(img).astype(img.dtype)\n",
    "    bg = bg[:, :img.shape[1] // 4]\n",
    "    img = np.concatenate([bg, img, bg], 1)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # lenear interpolate\n",
    "    return (img / 255).astype('float32')\n",
    "\n",
    "# https://github.com/xingyizhou/CenterNet/blob/819e0d0dde02f7b8cb0644987a8d3a370aa8206a/src/lib/utils/image.py\n",
    "# heatmap: H, W\n",
    "# center : X(w direction), Y(H direction)\n",
    "##################### mu_x = int(center[0] + 0.5) CAUSES BUG ##################################\n",
    "def old_draw_msra_gaussian(heatmap, center, sigma):\n",
    "    tmp_size = sigma * 3\n",
    "    mu_x = int(center[0] + 0.5)\n",
    "    mu_y = int(center[1] + 0.5)\n",
    "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "        return heatmap\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = np.arange(0, size, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "    x0 = y0 = size // 2\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "    img_x = max(0, ul[0]), min(br[0], h)\n",
    "    img_y = max(0, ul[1]), min(br[1], w)\n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "      heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "      g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "    return heatmap\n",
    "def draw_msra_gaussian(heatmap, center, sigma):\n",
    "    # tmp_size = sigma * 3\n",
    "    tmp_size = np.ceil(sigma * 3).astype(int)  # tmp_size should be int for readability ( and to remove bug ? )\n",
    "    mu_x = int(center[0])\n",
    "    mu_y = int(center[1])\n",
    "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "        return heatmap\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = np.arange(0, size, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "    x0 = y0 = size // 2\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "    img_x = max(0, ul[0]), min(br[0], h)\n",
    "    img_y = max(0, ul[1]), min(br[1], w)\n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "      heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "      g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "    return heatmap\n",
    "\n",
    "def gaussian2D(shape, sigma=1):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m+1,-n:n+1]\n",
    "\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    return h\n",
    "\n",
    "def draw_umich_gaussian(heatmap, center, radius, k=1):\n",
    "    diameter = 2 * radius + 1\n",
    "    gaussian = gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "    \n",
    "    x, y = int(center[0]), int(center[1])\n",
    "\n",
    "    height, width = heatmap.shape[0:2]\n",
    "      \n",
    "    left, right = min(x, radius), min(width - x, radius + 1)\n",
    "    top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "    masked_heatmap  = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "    masked_gaussian = gaussian[radius - top:radius + bottom, radius - left:radius + right]\n",
    "    if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0: # TODO debug\n",
    "        np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)\n",
    "    return heatmap\n",
    "\n",
    "def make_heatmap(m, v_arr, u_arr, z_arr):\n",
    "    for v,u,z in zip(v_arr, u_arr, z_arr):\n",
    "        # sigma = 1000 / 3.  / z / MODEL_SCALE\n",
    "        sigma = 800 / 3.  / z / MODEL_SCALE\n",
    "        m = draw_msra_gaussian(m, (u,v), sigma)\n",
    "    return m\n",
    "        \n",
    "#def get_mask_and_regr(img, labels):\n",
    "#    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "#    regr = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 7], dtype='float32')\n",
    "#    coords = str2coords(labels)\n",
    "#    xs, ys = get_img_coords(labels)\n",
    "#    z_arr = [e[\"z\"] for e in coords]\n",
    "#    \n",
    "#    mask_V_arr_float, mask_U_arr_float = VU2maskVU( ys, xs )\n",
    "#    # use floor floowing paper\n",
    "#    mask_V_arr = np.floor( mask_V_arr_float ).astype('int')\n",
    "#    mask_U_arr = np.floor( mask_U_arr_float ).astype('int')\n",
    "#    mask_V_diff = mask_V_arr_float - mask_V_arr\n",
    "#    mask_U_diff = mask_U_arr_float - mask_U_arr\n",
    "#\n",
    "#    # make heatmap\n",
    "#    mask = make_heatmap(mask, mask_V_arr, mask_U_arr, z_arr)\n",
    "#    \n",
    "#    for mask_V,mask_U, vdiff,udiff, regr_dict in zip(mask_V_arr,mask_U_arr,mask_V_diff,mask_U_diff, coords):\n",
    "#        if mask_V >= 0 and mask_V < IMG_HEIGHT // MODEL_SCALE and mask_U >= 0 and mask_U < IMG_WIDTH // MODEL_SCALE:\n",
    "#            regr_dict = _regr_preprocess(regr_dict, vdiff, udiff)\n",
    "#            regr[mask_V, mask_U] = [regr_dict[n] for n in sorted(regr_dict)]\n",
    "#    return mask, regr\n",
    "def get_mask_and_regr(img, labels, aug=False):\n",
    "    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n",
    "    regr = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 7], dtype='float32')\n",
    "    coords = str2coords(labels)\n",
    "    xs, ys = get_img_coords(labels)\n",
    "    z_arr = [e[\"z\"] for e in coords]\n",
    "    \n",
    "    mask_V_arr_float, mask_U_arr_float = VU2maskVU( ys, xs )\n",
    "    if aug:\n",
    "        VU_JITTER_MIN = 0.3\n",
    "        ###VU_JITTER = np.maximum(VU_JITTER_MIN,   2 * (800./ np.array(z_arr) / 3.) / MODEL_SCALE)  # jitter diameter = sigma\n",
    "        VU_JITTER = np.maximum(VU_JITTER_MIN,   2 * (800. / 3. / np.array(z_arr) / MODEL_SCALE) / 3.  )  # jitter diameter = sigma/2\n",
    "        mask_V_arr_float += VU_JITTER * ( np.random.rand(len(mask_V_arr_float)) - 0.5)\n",
    "        mask_U_arr_float += VU_JITTER * ( np.random.rand(len(mask_U_arr_float)) - 0.5)\n",
    "\n",
    "    # use floor floowing paper\n",
    "    mask_V_arr = np.floor( mask_V_arr_float ).astype('int')\n",
    "    mask_U_arr = np.floor( mask_U_arr_float ).astype('int')\n",
    "    mask_V_diff = mask_V_arr_float - mask_V_arr\n",
    "    mask_U_diff = mask_U_arr_float - mask_U_arr\n",
    "\n",
    "    # make heatmap\n",
    "    mask = make_heatmap(mask, mask_V_arr, mask_U_arr, z_arr)\n",
    "    \n",
    "    for mask_V,mask_U, vdiff,udiff, regr_dict in zip(mask_V_arr,mask_U_arr,mask_V_diff,mask_U_diff, coords):\n",
    "        if mask_V >= 0 and mask_V < IMG_HEIGHT // MODEL_SCALE and mask_U >= 0 and mask_U < IMG_WIDTH // MODEL_SCALE:\n",
    "            regr_dict = _regr_preprocess(regr_dict, vdiff, udiff)\n",
    "            regr[mask_V, mask_U] = [regr_dict[n] for n in sorted(regr_dict)]\n",
    "    return mask, regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e735fd9c-d367-4374-bcd9-c33753ebbe6d"
    }
   },
   "outputs": [],
   "source": [
    "# check _regr_preprocess and regr_back\n",
    "# especially check pitch\n",
    "xyz = [3.,6.,24.]\n",
    "__reg = _regr_preprocess({\"id\":\"_test\",\"x\":xyz[0],\"y\":xyz[1],\"z\":xyz[2], \"yaw\":0.2,\"pitch\":-1.11,\"roll\":0. }, 0,0)\n",
    "print(__reg)\n",
    "u,v = XYZ2UV(xyz[0],xyz[1],xyz[2])\n",
    "ma_v, ma_u = VU2maskVU(v, u)\n",
    "\n",
    "__regbak = _regr_back(__reg, ma_v, ma_u)\n",
    "print(__regbak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TEST Mask Jittering ###\n",
    "def vis_mask(img, mask):\n",
    "    _mm = np.repeat( np.repeat(mask, 8, axis=0), 8, axis=1 )[:,:, None]\n",
    "    _mm = np.repeat(_mm, 3, axis=-1)\n",
    "    _mm [:,:,1] = 0 ; _mm[:,:,2] = 0\n",
    "    \n",
    "    tmp =  np.clip( 0.8 * img + 0.4 * _mm, 0,1)\n",
    "    tmp[ _mm[:,:,0]==1 ] = [0,1,1]\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow( tmp , alpha=0.3)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "tmp_idx = 2\n",
    "img0 = imread(PATH + 'train_images/' + train['ImageId'][tmp_idx] + '.jpg')\n",
    "img = preprocess_image(img0)\n",
    "\n",
    "mask, regr = get_mask_and_regr(img0, train['PredictionString'][tmp_idx], aug=True)\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(img)\n",
    "\n",
    "vis_mask(img, mask)\n",
    "mask, regr = get_mask_and_regr(img0, train['PredictionString'][tmp_idx], aug=True)\n",
    "vis_mask(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "386e5507-3b78-4ccf-8b4d-242e8c2c09be"
    }
   },
   "outputs": [],
   "source": [
    "tmp_idx = 2\n",
    "img0 = imread(PATH + 'train_images/' + train['ImageId'][tmp_idx] + '.jpg')\n",
    "img = preprocess_image(img0)\n",
    "\n",
    "mask, regr = get_mask_and_regr(img0, train['PredictionString'][tmp_idx])\n",
    "\n",
    "print('img.shape', img.shape, 'std:', np.std(img))\n",
    "print('mask.shape', mask.shape, 'std:', np.std(mask))\n",
    "print('mask.max', mask.shape, 'max:', np.max(mask))\n",
    "print('regr.shape', regr.shape, 'std:', np.std(regr))\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Processed image')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Detection haetmap')\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Detection Mask')\n",
    "plt.imshow(mask == 1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Image + Detection Mask')\n",
    "_mm = np.repeat( np.repeat(mask, 8, axis=0), 8, axis=1 )[:,:, None]\n",
    "plt.imshow(0.6 * img + 0.4 * _mm, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "assert(regr.shape[2] == len(REGR_TARGETS))\n",
    "for _i, _name in enumerate(REGR_TARGETS):\n",
    "    # print(_name + \" vals\", regr[:,:,_i][ mask == 1 ])\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title(\"[{}]  min|max= {} | {}\".format(_name, np.min(regr[:,:,_i]), np.max(regr[:,:,_i]) ))\n",
    "    plt.imshow(regr[:,:,_i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "703a5e69-4d06-4561-ace1-bfe792a05245"
    }
   },
   "outputs": [],
   "source": [
    "# CHECK PITCH\n",
    "tmp_idx = 0\n",
    "tmp_cor_idx = 3\n",
    "img0 = imread(PATH + 'train_images/' + train['ImageId'][tmp_idx] + '.jpg')\n",
    "img = preprocess_image(img0)\n",
    "\n",
    "mask, regr = get_mask_and_regr(img0, train['PredictionString'][tmp_idx])\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "si_id = REGR_TARGETS.index(\"pitch_sin\")\n",
    "co_id = REGR_TARGETS.index(\"pitch_cos\")\n",
    "if True:\n",
    "    tmp_varr,tmp_uarr = np.where(mask==1)\n",
    "    _v,_u = tmp_varr[tmp_cor_idx], tmp_uarr[tmp_cor_idx]\n",
    "    si = regr[_v, _u, si_id]\n",
    "    co = regr[_v, _u, co_id]\n",
    "    pitch_from_car = np.arccos(co) * np.sign(si)\n",
    "    # print(\"pitch-from-car(rad)\",pitch_from_car)\n",
    "    # print(\"pitch-from-car(deg)\",180. / np.pi * pitch_from_car)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.title(\"pitch-from-car(deg) = {}\".format( 180. / np.pi * pitch_from_car))\n",
    "    tmpmat = img.copy()\n",
    "    tmpmat[8*_v -8: 8*_v +8, 8*_u -8 : 8*_u  +8] = [255,0,255]\n",
    "    plt.imshow(tmpmat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "79072029-2fef-4ae9-a071-ab86ae083573"
    }
   },
   "source": [
    "# PywTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "nbpresent": {
     "id": "89e7fbe4-09dc-46c2-9498-582a0b959727"
    }
   },
   "outputs": [],
   "source": [
    "class CarDataset(Dataset):\n",
    "    \"\"\"Car dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, root_dir, mask_root_dir, training=True, data_aug=False):\n",
    "        self.df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.mask_root_dir = mask_root_dir  # ignore mask\n",
    "        self.training = training\n",
    "        self.data_aug = data_aug\n",
    "        if data_aug:\n",
    "            self.data_aug_func = train_aug_trasforms = alb.Compose([\n",
    "                alb.RandomBrightnessContrast(0.05, 0.05, p=0.2),\n",
    "                alb.GaussNoise(var_limit=(10.0, 50.0), p=0.1),\n",
    "            ], p=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Get image name\n",
    "        idx, labels = self.df.values[idx]\n",
    "        img_name = self.root_dir.format(idx)\n",
    "        \n",
    "        ## Read image\n",
    "        #img0 = imread(img_name, True)  #old\n",
    "        img0 = cv2.imread(img_name)[:,:,::-1]\n",
    "        if self.data_aug:\n",
    "            img0 = self.data_aug_func(image=img0)[\"image\"]\n",
    "        img = preprocess_image(img0.astype(float))\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "        \n",
    "        ## Read ignore mask\n",
    "        #ign_img0 = imread(self.mask_root_dir.format(idx), True)\n",
    "        #do not resize, just use it# ign_img = preprocess_mask_image(ign_img0)\n",
    "        ign_img0 = cv2.imread(self.mask_root_dir.format(idx), cv2.IMREAD_GRAYSCALE)\n",
    "        if ign_img0 is None:  # some pics has NO MASK\n",
    "            ign_img0 = np.zeros((ORIG_H, ORIG_W), dtype='float32')\n",
    "\n",
    "        ign_img = np.array(ign_img0).astype('float32') / 255.\n",
    "        # ign_img = np.rollaxis(ign_img, 2, 0)\n",
    "        ######################################################\n",
    "\n",
    "        # ignore mask for CNN\n",
    "        ign_img_for_feed = preprocess_mask_image(ign_img0)\n",
    "        ign_img_for_feed = np.expand_dims(ign_img_for_feed, 0)  # h,w -> 1,h,w\n",
    "        \n",
    "        \n",
    "        # Get mask and regression maps\n",
    "        if self.training:\n",
    "            mask, regr = get_mask_and_regr(img0, labels, self.data_aug)\n",
    "            regr = np.rollaxis(regr, 2, 0)\n",
    "        else:\n",
    "            mask, regr = 0, 0\n",
    "        \n",
    "        return [img, mask, regr, ign_img, ign_img_for_feed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "10c1f8eb-c9a7-4338-a49a-94820b68449f"
    }
   },
   "outputs": [],
   "source": [
    "train_images_dir = PATH + 'train_images/{}.jpg'\n",
    "test_images_dir = PATH + 'test_images/{}.jpg'\n",
    "train_masks_dir = PATH + 'train_masks/{}.jpg'\n",
    "test_masks_dir = PATH + 'test_masks/{}.jpg'\n",
    "\n",
    "### df_train, df_dev = train_test_split(train, test_size=0.01, random_state=42)\n",
    "df_train, df_dev = train_test_split(train, test_size=0.1, random_state=1042)\n",
    "df_test = test\n",
    "\n",
    "## Create dataset objects\n",
    "train_dataset = CarDataset(df_train, train_images_dir, train_masks_dir, data_aug=True)\n",
    "###train_dataset = CarDataset(df_train, train_images_dir, train_masks_dir, data_aug=False)\n",
    "dev_dataset = CarDataset(df_dev, train_images_dir, train_masks_dir)\n",
    "test_dataset = CarDataset(df_test, test_images_dir, test_masks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "28e926de-685f-40ff-b4c1-17d2891c96ca"
    }
   },
   "outputs": [],
   "source": [
    "if False:  # for data aug test\n",
    "    img, mask, regr, ign_mask, ign_mask_for_feed = train_dataset[81]\n",
    "    plt.figure(figsize=(40,40))\n",
    "    plt.imshow(np.rollaxis(img, 0, 3))\n",
    "    plt.show()\n",
    "    cv2.imwrite(\"a.png\", np.rollaxis(img, 0, 3) * 255)\n",
    "if False:    \n",
    "    img, mask, regr, ign_mask, ign_mask_for_feed = train_dataset[50]\n",
    "    plt.figure(figsize=(40,40))\n",
    "    plt.imshow(np.rollaxis(img, 0, 3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "712be082-550b-4a78-9b41-0ecf07098d18"
    }
   },
   "outputs": [],
   "source": [
    "#img, mask, regr = train_dataset[0]\n",
    "img, mask, regr, ign_mask, ign_mask_for_feed = dev_dataset[0]\n",
    "print(img.shape)\n",
    "print(mask.shape)\n",
    "print(ign_mask.shape)\n",
    "print(ign_mask_for_feed.shape)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(np.rollaxis(img, 0, 3))\n",
    "plt.show()\n",
    "if False:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title(\"img + mask\")\n",
    "    plt.imshow(0.5 * np.rollaxis(img, 0, 3) + 0.5 * np.repeat(ign_mask_for_feed[0][:,:,None], 3, axis=-1) )\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.title('Image + Detection Mask Peak Point')\n",
    "tmp = np.rollaxis(img, 0, 3).copy()\n",
    "tmp[ np.repeat(np.repeat(mask, 8, axis=0), 8,axis=1) == 1 ] = [0,255,255]\n",
    "plt.imshow(tmp)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.title('Image + Detection Mask Peak Point +  IgnoreMask')\n",
    "tmp[ ign_mask_for_feed[0] == 1 ] = [255,0,255]\n",
    "plt.imshow(tmp)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.title('Image + Detection Mask')\n",
    "_mm = np.repeat( np.repeat(mask, 8, axis=0), 8, axis=1 )[:,:, None]\n",
    "#plt.imshow(0.6 * np.rollaxis(img, 0, 3) + 0.4 * _mm, alpha=0.3)\n",
    "_mm = np.repeat(_mm, 3, axis=-1)\n",
    "_mm [:,:,1] = 0 ; _mm[:,:,2] = 0\n",
    "plt.imshow(0.8 * np.rollaxis(img, 0, 3) + 0.4 * _mm , alpha=0.3)\n",
    "plt.show()\n",
    "if False:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(regr[-1])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #plt.imshow(ign_mask)\n",
    "    #plt.show()\n",
    "\n",
    "print( np.where(mask == 1) )\n",
    "print( np.where(regr[-1] > 0 )  )  #z\n",
    "print( regr[-1][regr[-1] > 0 ]  )  #z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "a236dbf8-5694-42de-a155-e5db71eb832c"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "# Create data generators - they will produce batches\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bbcc6c77-29a9-4794-8fcf-c8c58ac8f935"
    }
   },
   "source": [
    "# PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "a14d8f04-8d2c-42ba-88f3-969432e9afec"
    }
   },
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        \n",
    "        # for padding issues, see \n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        \n",
    "        if x2 is not None:\n",
    "            x = torch.cat([x2, x1], dim=1)\n",
    "        else:\n",
    "            x = x1\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "def get_mesh(batch_size, shape_x, shape_y):\n",
    "    mg_x, mg_y = np.meshgrid(np.linspace(0, 1, shape_y), np.linspace(0, 1, shape_x))\n",
    "    mg_x = np.tile(mg_x[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
    "    mg_y = np.tile(mg_y[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
    "    mesh = torch.cat([torch.tensor(mg_x).to(device), torch.tensor(mg_y).to(device)], 1)\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9d436955-7847-438b-97bd-1ad901351ca6"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.GroupNorm(16, planes)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.GroupNorm(16, planes)\n",
    "\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(inplanes, planes, stride), nn.GroupNorm(16, planes))\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = F.relu(out, inplace=True)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.GroupNorm(16, planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.GroupNorm(16, planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.GroupNorm(16, planes * self.expansion)\n",
    "\n",
    "        if stride != 1 or inplanes != planes * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(inplanes, planes * self.expansion, stride), \n",
    "                nn.GroupNorm(16, planes * self.expansion))\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
    "        out = self.bn3(self.conv3(out))\n",
    " \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetFeatures(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False, input_channels=3):\n",
    "        super(ResNetFeatures, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.GroupNorm(16, 64)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        conv1 = F.max_pool2d(conv1, 3, stride=2, padding=1)\n",
    "\n",
    "        feats4 = self.layer1(conv1)\n",
    "        feats8 = self.layer2(feats4)\n",
    "        feats16 = self.layer3(feats8)\n",
    "        feats32 = self.layer4(feats16)\n",
    "\n",
    "        return feats8, feats16, feats32\n",
    "\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNetFeatures(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        _load_pretrained(model, model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNetFeatures(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        _load_pretrained(model, model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def _load_pretrained(model, pretrained):\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained = {k : v for k, v in pretrained.items() if k in model_dict}\n",
    "    model_dict.update(pretrained)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "785e5bb6-8333-42bc-9275-e2bd63dff890"
    }
   },
   "outputs": [],
   "source": [
    "USEMASK = True\n",
    "\n",
    "class CentResnet(nn.Module):\n",
    "    '''Mixture of previous classes'''\n",
    "    def __init__(self, n_classes):\n",
    "        super(CentResnet, self).__init__()\n",
    "        self.base_model = resnet18(pretrained=False, input_channels=6)\n",
    "        \n",
    "        # Lateral layers convert resnet outputs to a common feature size\n",
    "        self.lat8 = nn.Conv2d(128, 256, 1)\n",
    "        self.lat16 = nn.Conv2d(256, 256, 1)\n",
    "        self.lat32 = nn.Conv2d(512, 256, 1)\n",
    "        self.bn8 = nn.GroupNorm(16, 256)\n",
    "        self.bn16 = nn.GroupNorm(16, 256)\n",
    "        self.bn32 = nn.GroupNorm(16, 256)\n",
    "\n",
    "        if USEMASK:\n",
    "            self.conv0 = double_conv(5 + 1, 64)\n",
    "        else:\n",
    "            self.conv0 = double_conv(5, 64)\n",
    "            \n",
    "        self.conv1 = double_conv(64, 128)\n",
    "        self.conv2 = double_conv(128, 512)\n",
    "        self.conv3 = double_conv(512, 1024)\n",
    "        \n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.up1 = up(1282 , 512) #+ 1024\n",
    "        self.up2 = up(512 + 512, 256)\n",
    "        self.outc = nn.Conv2d(256, n_classes, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        mesh1 = get_mesh(batch_size, x.shape[2], x.shape[3])\n",
    "        x0 = torch.cat([x, mesh1], 1)\n",
    "        x1 = self.mp(self.conv0(x0))\n",
    "        x2 = self.mp(self.conv1(x1))\n",
    "        x3 = self.mp(self.conv2(x2))\n",
    "        x4 = self.mp(self.conv3(x3))\n",
    "        \n",
    "        #feats = self.base_model.extract_features(x)\n",
    "                # Run frontend network\n",
    "        if USEMASK:\n",
    "            ## feats8, feats16, feats32 = self.base_model(x[:,0:3])  ## use first 3 channel. this may not be proper way\n",
    "            feats8, feats16, feats32 = self.base_model(x0)  ## C=6 : rgb(3)+mask(1)+mesh(2)\n",
    "        else:\n",
    "            feats8, feats16, feats32 = self.base_model(x)\n",
    "\n",
    "        lat8 = F.relu(self.bn8(self.lat8(feats8)))\n",
    "        lat16 = F.relu(self.bn16(self.lat16(feats16)))\n",
    "        lat32 = F.relu(self.bn32(self.lat32(feats32)))\n",
    "        \n",
    "        # Add positional info\n",
    "        mesh2 = get_mesh(batch_size, lat32.shape[2], lat32.shape[3])\n",
    "        feats = torch.cat([lat32, mesh2], 1)\n",
    "        #print(feats.shape)\n",
    "        #print (x4.shape)\n",
    "        x = self.up1(feats, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train params and some check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f366ee6d-c701-45db-a340-a5b9e4da26ae"
    }
   },
   "outputs": [],
   "source": [
    "## Constants\n",
    "SWITCH_LOSS_EPOCH = -1 # 5\n",
    "n_epochs = 10  # 12 #6\n",
    "\n",
    "# Gets the GPU if there is one, otherwise the cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CentResnet(8).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0009)\n",
    "### optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "#optimizer =  RAdam(model.parameters(), lr = 0.001)\n",
    "\n",
    "EPOCH_STEPS = 1 * len(train_loader)\n",
    "\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=max(n_epochs, 10) * len(train_loader) // 3, gamma=0.1)\n",
    "\n",
    "##exp_lr_scheduler = lr_scheduler. MultiStepLR(optimizer, \n",
    "#   milestones=[int(EPOCH_STEPS*6), int(EPOCH_STEPS*10)], gamma=0.1)  #6.4.2\n",
    "#    milestones=[int(EPOCH_STEPS*10)], gamma=0.1)  #\n",
    "#    milestones=[int(EPOCH_STEPS*100)], gamma=0.5)  # constant LR\n",
    "#    milestones=[int(EPOCH_STEPS*9), int(EPOCH_STEPS*15)], gamma=0.1)  # 9.6.2\n",
    "#    milestones=[int(EPOCH_STEPS*6), int(EPOCH_STEPS*10)], gamma=0.1)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-3*1e-3, factor=1./9.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ad273bed-93a6-405c-9c2a-09f41ff74b5d"
    }
   },
   "outputs": [],
   "source": [
    "if USEMASK:\n",
    "    img_batch = torch.randn((1,3 + 1,512,2048))\n",
    "else:\n",
    "    img_batch = torch.randn((1,3,512,2048))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ed9479a6-f494-40fa-846b-b9d6b02a9948"
    }
   },
   "outputs": [],
   "source": [
    "test = model(img_batch.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f3d366b8-c0ac-4194-abc9-23fbf0e02e5d"
    }
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'../input/centernet2/model.pth'))\n",
    "#model.load_state_dict(torch.load(f'../input/r2-center-resnet/model.pth', map_location='cpu'))\n",
    "#model.load_state_dict(torch.load(f'./run9-lrSchedule6-4-2.work/model_epoch_16.pth'))\n",
    "#model.load_state_dict(torch.load(f'./model_epoch_16.pth'))\n",
    "#model.load_state_dict(torch.load(f'../input/r2-center-resnet/model.pth'))\n",
    "#model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "4a74a8a2-7c49-455a-a66e-9951011f89f3"
    }
   },
   "outputs": [],
   "source": [
    "def infer_image(img, ign_mask_for_feed):  # shape:[B,C,H,W]\n",
    "    return model( torch.from_numpy( np.concatenate((img, ign_mask_for_feed),axis=1) ).to(device) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POST PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "######## def postprocess_heatmap(logits, thresh=0.60):  # V6+ignMask, LB0.062\n",
    "######## def postprocess_heatmap(logits, thresh=0.50):  # V6+ignMask, LB0.066\n",
    "######## def postprocess_heatmap(logits, thresh=0.40):  # V6+ignMask, LB0.065\n",
    "######## def postprocess_heatmap(logits, thresh=0.30):  # V6+ignMask, LB0.063\n",
    "\n",
    "### def postprocess_heatmap(logits, thresh=0.4):\n",
    "def postprocess_heatmap(logits, thresh=0.45):\n",
    "    prob = sigmoid(logits)\n",
    "    mp2d = torch.nn.MaxPool2d(3, stride=1, padding=1, dilation=1, return_indices=False, ceil_mode=False)\n",
    "    out = mp2d( torch.Tensor([[prob]]) ).numpy()[0][0]\n",
    "    return (prob == out) & (prob > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b6792e19-dd80-4de3-b4b4-10d135281a28"
    }
   },
   "outputs": [],
   "source": [
    "DISTANCE_THRESH_CLEAR = 2\n",
    "\n",
    "def convert_3d_to_2d(x, y, z, fx = 2304.5479, fy = 2305.8757, cx = 1686.2379, cy = 1354.9849):\n",
    "    # stolen from https://www.kaggle.com/theshockwaverider/eda-visualization-baseline\n",
    "    return x * fx / z + cx, y * fy / z + cy\n",
    "\n",
    "def optimize_xy(r, c, x0, y0, z0):\n",
    "    def distance_fn(xyz):\n",
    "        x, y, z = xyz\n",
    "        x, y = convert_3d_to_2d(x, y, z0)\n",
    "        y, x = x, y\n",
    "        x = (x - IMG_SHAPE[0] // 2) * IMG_HEIGHT / (IMG_SHAPE[0] // 2) / MODEL_SCALE\n",
    "        x = np.round(x).astype('int')\n",
    "        y = (y + IMG_SHAPE[1] // 4) * IMG_WIDTH / (IMG_SHAPE[1] * 1.5) / MODEL_SCALE\n",
    "        y = np.round(y).astype('int')\n",
    "        return (x-r)**2 + (y-c)**2\n",
    "\n",
    "    res = minimize(distance_fn, [x0, y0, z0], method='Powell')\n",
    "    x_new, y_new, z_new = res.x\n",
    "    return x_new, y_new, z0\n",
    "\n",
    "def clear_duplicates(coords):\n",
    "    for c1 in coords:\n",
    "        xyz1 = np.array([c1['x'], c1['y'], c1['z']])\n",
    "        for c2 in coords:\n",
    "            xyz2 = np.array([c2['x'], c2['y'], c2['z']])\n",
    "            distance = np.sqrt(((xyz1 - xyz2)**2).sum())\n",
    "            if distance < DISTANCE_THRESH_CLEAR:\n",
    "                if c1['confidence'] < c2['confidence']:\n",
    "                    c1['confidence'] = -1\n",
    "    return [c for c in coords if c['confidence'] > 0]\n",
    "\n",
    "def extract_coords(prediction, ign_mask):\n",
    "    assert ign_mask.shape[0] == ORIG_H   #\n",
    "    logits = prediction[0]\n",
    "    regr_output = prediction[1:]\n",
    "    ##OLD simple threthold### points = np.argwhere(logits > 0)\n",
    "    points_mat = postprocess_heatmap(logits) \n",
    "    points = np.argwhere( points_mat > 0 )\n",
    "    \n",
    "    # OLD # col_names = sorted(['x', 'y', 'z', 'yaw', 'pitch_sin', 'pitch_cos', 'roll'])\n",
    "    col_names = sorted(REGR_TARGETS)  # vdiff,udiff,z,yaw,pitch_sin,pitch_cos,roll\n",
    "    coords = []\n",
    "    for r, c in points:           \n",
    "        regr_dict = dict(zip(col_names, regr_output[:, r, c]))\n",
    "        \n",
    "        # use heatmap-peak (V,U) position\n",
    "        regr_backed = _regr_back(regr_dict, r, c)\n",
    "        \n",
    "        _U, _V = XYZ2UV(regr_backed[\"x\"], regr_backed[\"y\"], regr_backed[\"z\"])\n",
    "        _U, _V = int(_U), int(_V)\n",
    "        if _V>=0 and _V<ORIG_H and _U>=0 and _U<ORIG_W and ign_mask[_V,_U] > 0.5:  # floor(u), floor(v)\n",
    "            # print(\"point is in ignore_mask\")\n",
    "            continue\n",
    "\n",
    "        coords.append(regr_backed)\n",
    "        coords[-1]['confidence'] = 1 / (1 + np.exp(-logits[r, c]))\n",
    "        #coords[-1]['x'], coords[-1]['y'], coords[-1]['z'] = optimize_xy(r, c, coords[-1]['x'], coords[-1]['y'], coords[-1]['z'])\n",
    "        ## V4: r,c is now floor(float val of mask_UV ), so add 0.5\n",
    "        ## V5: do not do optmizer()\n",
    "        # coords[-1]['x'], coords[-1]['y'], coords[-1]['z'] = optimize_xy(r+0.5, c+0.5, coords[-1]['x'], coords[-1]['y'], coords[-1]['z'])\n",
    "\n",
    "        coords = clear_duplicates(coords)\n",
    "    return coords\n",
    "\n",
    "def coords2str(coords, names=['yaw', 'pitch', 'roll', 'x', 'y', 'z', 'confidence']):\n",
    "    s = []\n",
    "    for c in coords:\n",
    "        for n in names:\n",
    "            s.append(str(c.get(n, 0)))\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mAP calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1fa14caf-4b98-47df-8e77-2672730750b5"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from math import sqrt, acos, pi, sin, cos\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.metrics import average_precision_score\n",
    "from multiprocessing import Pool\n",
    "import functools\n",
    "\n",
    "def expand_df(df, PredictionStringCols):\n",
    "    df = df.dropna().copy()\n",
    "    df['NumCars'] = [int((x.count(' ')+1)/7) for x in df['PredictionString']]\n",
    "\n",
    "    #image_id_expanded = [item for item, count in zip(df['ImageId'], df['NumCars']) for i in range(count)]\n",
    "    ##prediction_strings_expanded = df['PredictionString'].str.split(' ',expand = True).values.reshape(-1,7).astype(float)\n",
    "    ##prediction_strings_expanded = prediction_strings_expanded[~np.isnan(prediction_strings_expanded).all(axis=1)]\n",
    "\n",
    "    assert len(PredictionStringCols) == 7\n",
    "    idarr = []\n",
    "    tmparr = []\n",
    "    for imgid, predstr in zip( df['ImageId'], df['PredictionString']):\n",
    "        if predstr == \"\":\n",
    "            continue\n",
    "        coords = np.array(predstr.split(' ')).reshape(-1,7).astype(float)\n",
    "        for cor in coords:\n",
    "            idarr.append(imgid)\n",
    "            tmparr.append(  cor.tolist() )\n",
    "    \n",
    "    prediction_strings_expanded = np.array(tmparr)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "#            'ImageId': image_id_expanded,\n",
    "            'ImageId': idarr,\n",
    "            PredictionStringCols[0]:prediction_strings_expanded[:,0],\n",
    "            PredictionStringCols[1]:prediction_strings_expanded[:,1],\n",
    "            PredictionStringCols[2]:prediction_strings_expanded[:,2],\n",
    "            PredictionStringCols[3]:prediction_strings_expanded[:,3],\n",
    "            PredictionStringCols[4]:prediction_strings_expanded[:,4],\n",
    "            PredictionStringCols[5]:prediction_strings_expanded[:,5],\n",
    "            PredictionStringCols[6]:prediction_strings_expanded[:,6]\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def str2coords_dev(s, names):\n",
    "    coords = []\n",
    "    for l in np.array(s.split()).reshape([-1, 7]):\n",
    "        coords.append(dict(zip(names, l.astype('float'))))\n",
    "    return coords\n",
    "\n",
    "def TranslationDistance(p,g, abs_dist = False):\n",
    "    dx = p['x'] - g['x']\n",
    "    dy = p['y'] - g['y']\n",
    "    dz = p['z'] - g['z']\n",
    "    diff0 = (g['x']**2 + g['y']**2 + g['z']**2)**0.5\n",
    "    diff1 = (dx**2 + dy**2 + dz**2)**0.5\n",
    "    if abs_dist:\n",
    "        diff = diff1\n",
    "    else:\n",
    "        diff = diff1/diff0\n",
    "    return diff\n",
    "\n",
    "def RotationDistance(p, g):\n",
    "    true=[ g['pitch'] ,g['yaw'] ,g['roll'] ]\n",
    "    pred=[ p['pitch'] ,p['yaw'] ,p['roll'] ]\n",
    "    q1 = R.from_euler('xyz', true)\n",
    "    q2 = R.from_euler('xyz', pred)\n",
    "    diff = R.inv(q2) * q1\n",
    "    W = np.clip(diff.as_quat()[-1], -1., 1.)\n",
    "    \n",
    "    # in the official metrics code:\n",
    "    # https://www.kaggle.com/c/pku-autonomous-driving/overview/evaluation\n",
    "    #   return Object3D.RadianToDegree( Math.Acos(diff.W) )\n",
    "    # this code treat θ and θ+2π differntly.\n",
    "    # So this should be fixed as follows.\n",
    "    W = (acos(W)*360)/pi\n",
    "    if W > 180:\n",
    "        W = 360 - W\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "20da8dd0-d2e1-4898-b9c0-a19911f38306"
    }
   },
   "outputs": [],
   "source": [
    "thres_tr_list = [0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01]\n",
    "thres_ro_list = [50, 45, 40, 35, 30, 25, 20, 15, 10, 5]\n",
    "\n",
    "def check_match(train_df, valid_df, idx):  # train_df==TrueLabel, valid_df==Prediction\n",
    "    keep_gt=False\n",
    "    thre_tr_dist = thres_tr_list[idx]\n",
    "    thre_ro_dist = thres_ro_list[idx]\n",
    "    train_dict = {imgID:str2coords_dev(s, names=['carid_or_score', 'pitch', 'yaw', 'roll', 'x', 'y', 'z']) for imgID,s in zip(train_df['ImageId'],train_df['PredictionString'])}\n",
    "    valid_dict = {imgID:str2coords_dev(s, names=['pitch', 'yaw', 'roll', 'x', 'y', 'z', 'carid_or_score']) for imgID,s in zip(valid_df['ImageId'],valid_df['PredictionString'])}\n",
    "    result_flg = [] # 1 for TP, 0 for FP\n",
    "    scores = []\n",
    "    MAX_VAL = 10**10\n",
    "    for img_id in valid_dict:\n",
    "        for pcar in sorted(valid_dict[img_id], key=lambda x: -x['carid_or_score']):\n",
    "            # find nearest GT\n",
    "            min_tr_dist = MAX_VAL\n",
    "            min_idx = -1\n",
    "            for idx, gcar in enumerate(train_dict[img_id]):\n",
    "                tr_dist = TranslationDistance(pcar,gcar)\n",
    "                if tr_dist < min_tr_dist:\n",
    "                    min_tr_dist = tr_dist\n",
    "                    min_ro_dist = RotationDistance(pcar,gcar)\n",
    "                    min_idx = idx\n",
    "                    \n",
    "            # set the result\n",
    "            if min_tr_dist < thre_tr_dist and min_ro_dist < thre_ro_dist:\n",
    "                if not keep_gt:\n",
    "                    train_dict[img_id].pop(min_idx)\n",
    "                result_flg.append(1)\n",
    "            else:\n",
    "                result_flg.append(0)\n",
    "            scores.append(pcar['carid_or_score'])\n",
    "    \n",
    "    return result_flg, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "40b83fdd-dca8-411c-ac41-bb0d1d2d1f5f"
    }
   },
   "outputs": [],
   "source": [
    "_train_df = pd.read_csv('../input/pku-autonomous-driving/train.csv')\n",
    "\n",
    "def calc_map(valid_df):\n",
    "    if np.all( valid_df.dropna().PredictionString == \"\" ):  # no pred\n",
    "        #print(\"warn: no prediction\")\n",
    "        return 0.0\n",
    "\n",
    "    expanded_valid_df = expand_df(valid_df, ['pitch','yaw','roll','x','y','z','Score'])\n",
    "\n",
    "    val_label_df = _train_df[_train_df.ImageId.isin(valid_df.ImageId.unique())]\n",
    "    # data description page says, The pose information is formatted as\n",
    "    # model type, yaw, pitch, roll, x, y, z\n",
    "    # but it doesn't, and it should be\n",
    "    # model type, pitch, yaw, roll, x, y, z\n",
    "    expanded_val_label_df = expand_df(val_label_df, ['model_type','pitch','yaw','roll','x','y','z'])\n",
    "\n",
    "    n_gt = len(expanded_val_label_df)\n",
    "    ap_list = []\n",
    "\n",
    "    ###max_workers = 10\n",
    "    ###p = Pool(processes=max_workers)\n",
    "    ###for result_flg, scores in p.imap(eval_func, range(10)):\n",
    "\n",
    "    eval_func = functools.partial(check_match, val_label_df, valid_df)\n",
    "\n",
    "    for _i in range(10):\n",
    "        result_flg, scores = eval_func(_i)\n",
    "\n",
    "        n_tp = np.sum(result_flg)\n",
    "        recall = n_tp/n_gt\n",
    "\n",
    "        ### randomized score version\n",
    "        ### https://www.kaggle.com/c/pku-autonomous-driving/discussion/124489\n",
    "        # ap = average_precision_score(result_flg, scores)*recall\n",
    "        if False:\n",
    "            ap = average_precision_score(result_flg, np.random.rand(len(result_flg)))*recall\n",
    "        else: # pure precision * recall\n",
    "            ap = np.mean(result_flg) * recall\n",
    "            # print(f\"precision/recall/F1 {np.mean(result_flg)}/{recall}/{ap}\")\n",
    "        ap_list.append(ap)\n",
    "\n",
    "    return np.mean(ap_list)\n",
    "\n",
    "def trim_below_threth(CV_df, threth):\n",
    "    cc = CV_df.copy()\n",
    "\n",
    "    tmparr = []\n",
    "    for st in cc.PredictionString:\n",
    "        if st == \"\":\n",
    "            tmparr.append(\"\")\n",
    "        else:\n",
    "            r = np.array([float(e) for e in st.split(\" \")]).reshape(-1,7)\n",
    "            r = r[ r[:,6] >= threth, :]\n",
    "            tmparr.append( \" \".join( [ str(e) for e in r.flatten()] ) )\n",
    "    cc.PredictionString = tmparr\n",
    "    return cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e410aa57-3992-4097-b484-ccb7a8904823"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "f5cfebaa-85d2-4526-a664-a0c7e063e091"
    }
   },
   "outputs": [],
   "source": [
    "# binary mask\n",
    "def _criterion_old(prediction, mask, regr,weight=0.4, size_average=True):\n",
    "    # Binary mask loss\n",
    "    pred_mask = torch.sigmoid(prediction[:, 0])\n",
    "#     mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - mask) * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
    "    mask_loss = mask * torch.log(pred_mask + 1e-12) + (1 - mask) * torch.log(1 - pred_mask + 1e-12)\n",
    "    mask_loss = -mask_loss.mean(0).sum()\n",
    "    \n",
    "    # Regression L1 loss\n",
    "    pred_regr = prediction[:, 1:]\n",
    "    regr_loss = (torch.abs(pred_regr - regr).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1)\n",
    "    regr_loss = regr_loss.mean(0)\n",
    "  \n",
    "    # Sum\n",
    "    loss = weight*mask_loss +(1-weight)* regr_loss\n",
    "    if not size_average:\n",
    "        loss *= prediction.shape[0]\n",
    "    return loss ,mask_loss , regr_loss\n",
    "\n",
    "def criterion_old2(prediction, heatmap, regr,weight=0.4, size_average=True):\n",
    "    mask = torch.eq(heatmap, 1)\n",
    "\n",
    "    # Binary mask loss\n",
    "    pred_mask = torch.sigmoid(prediction[:, 0])\n",
    "#     mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - mask) * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
    "    ### Loss of original paper\n",
    "    mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - heatmap)**4 * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
    "\n",
    "    mask_loss = -mask_loss.mean(0).sum()\n",
    "    \n",
    "    # Regression L1 loss\n",
    "    pred_regr = prediction[:, 1:]\n",
    "    regr_loss = (torch.abs(pred_regr - regr).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1)\n",
    "    regr_loss = regr_loss.mean(0)\n",
    "  \n",
    "    # Sum\n",
    "    loss = weight*mask_loss +(1-weight)* regr_loss\n",
    "    if not size_average:\n",
    "        loss *= prediction.shape[0]\n",
    "    return loss ,mask_loss , regr_loss\n",
    "\n",
    "def criterion(prediction, heatmap, regr, regr_weight=1., mask_weight=0.5):\n",
    "    mask = torch.eq(heatmap, 1)\n",
    "\n",
    "    # Binary mask loss\n",
    "    pred_mask = torch.sigmoid(prediction[:, 0])\n",
    "#     mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - mask) * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
    "    ### Loss of original paper\n",
    "    mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - heatmap)**4 * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
    "\n",
    "    mask_loss = -mask_loss.mean(0).sum()\n",
    "    \n",
    "    # Regression L1 loss\n",
    "    pred_regr = prediction[:, 1:]\n",
    "    regr_loss = (torch.abs(pred_regr - regr).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1)\n",
    "    regr_loss = regr_loss.mean(0)\n",
    "  \n",
    "    # Sum\n",
    "    loss = mask_weight * mask_loss + regr_weight * regr_loss\n",
    "    return loss ,mask_loss , regr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5831b6c3-110e-4b37-89ca-07a5bda44c97"
    }
   },
   "outputs": [],
   "source": [
    "## Just for checking the shapes to manage our Unet\n",
    "\n",
    "i = 0\n",
    "for batch_idx, (img_batch, mask_batch, regr_batch, ign_mask_batch, ign_mask_for_feed_batch) in enumerate(tqdm(train_loader)):\n",
    "#for batch_idx, (img_batch, mask_batch, regr_batch, ign_mask_batch) in enumerate(tqdm(train_loader)):\n",
    "#for batch_idx, (img_batch, mask_batch, regr_batch, ign_mask_batch) in enumerate(tqdm(test_loader)):\n",
    "    print(img_batch.shape)\n",
    "    print(mask_batch.shape)\n",
    "    print(regr_batch.shape)\n",
    "    print(ign_mask_batch.shape)\n",
    "    print(ign_mask_for_feed_batch.shape)\n",
    "    i+=1\n",
    "    if i>1:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "9c708bc8-794e-4d7c-822b-12e6c7f63056"
    }
   },
   "outputs": [],
   "source": [
    "def train_one(epoch, history=None):\n",
    "    model.train()\n",
    "    print('Train Epoch: {} \\tLR: {:.6f}'.format(epoch, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    t = tqdm(train_loader)\n",
    "    for batch_idx, (img_batch, mask_batch, regr_batch, ign_mask_batch, ign_mask_for_feed_batch) in enumerate(t):\n",
    "        #img_batch = img_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        regr_batch = regr_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        if USEMASK:\n",
    "            output = infer_image(img_batch, ign_mask_for_feed_batch)\n",
    "        else:\n",
    "            output = model(img_batch)\n",
    "\n",
    "        if epoch < SWITCH_LOSS_EPOCH :\n",
    "            loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch, regr_weight=0.1, mask_weight=0.9)\n",
    "            #loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch, 0.9)  # # 0 weight may degrate weight at switch\n",
    "            # loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch,0.95) \n",
    "        else:\n",
    "            loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch)\n",
    "        \n",
    "        t.set_description(f'train_loss (l={loss:.3f})(m={mask_loss:.2f}) (r={regr_loss:.4f}')\n",
    "        \n",
    "        if history is not None:\n",
    "            history.loc[epoch + batch_idx / len(train_loader), 'train_loss'] = loss.data.cpu().numpy()\n",
    "            history.loc[epoch + batch_idx / len(train_loader), 'train_mask_loss'] = mask_loss.data.cpu().numpy()\n",
    "            history.loc[epoch + batch_idx / len(train_loader), 'train_regr_loss'] = regr_loss.data.cpu().numpy()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        ################ TRY ReduceLROnPlateau ################ exp_lr_scheduler.step()\n",
    "    \n",
    "    print('  TrainLoss: {:.4f}\\tMaskLoss: {:.4f}\\tRegLoss: {:.4f}'.format(\n",
    "        history.query(f\"index >= {epoch}\").train_loss.mean(),\n",
    "        history.query(f\"index >= {epoch}\").train_mask_loss.mean(),\n",
    "        history.query(f\"index >= {epoch}\").train_regr_loss.mean() ))\n",
    "#        loss.data,\n",
    "#        mask_loss.data,\n",
    "#        regr_loss.data))\n",
    "\n",
    "def evaluate(epoch, history=None):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    valid_loss = 0\n",
    "    valid_mask_loss = 0\n",
    "    valid_regr_loss = 0\n",
    "    dev_predictions = []  # for mAP calc\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_batch, mask_batch, regr_batch, ign_mask_batch, ign_mask_for_feed_batch in dev_loader:\n",
    "            #img_batch = img_batch.to(device)\n",
    "\n",
    "            mask_batch = mask_batch.to(device)\n",
    "            regr_batch = regr_batch.to(device)\n",
    "\n",
    "            ##old#output = model(img_batch)\n",
    "            ##img_batch_withmask = torch.from_numpy( np.concatenate( (img_batch, ign_mask_for_feed_batch), axis=1 ) ).to(device)\n",
    "            ##output = model(img_batch_withmask)\n",
    "            output = infer_image(img_batch, ign_mask_for_feed_batch)\n",
    "\n",
    "            if epoch < SWITCH_LOSS_EPOCH :\n",
    "                loss,mask_loss, regr_loss= criterion(output, mask_batch, regr_batch, regr_weight=0.1, mask_weight=0.9)\n",
    "                valid_loss += loss.data\n",
    "                valid_mask_loss += mask_loss.data\n",
    "                valid_regr_loss += regr_loss.data\n",
    "            else :\n",
    "                loss,mask_loss, regr_loss = criterion(output, mask_batch, regr_batch)\n",
    "                valid_loss += loss.data\n",
    "                valid_mask_loss += mask_loss.data\n",
    "                valid_regr_loss += regr_loss.data\n",
    "\n",
    "            for out, ign_mask in zip(output.data.cpu().numpy(), ign_mask_batch):  # for mAP calc\n",
    "                coords = extract_coords(out, ign_mask)\n",
    "                s = coords2str(coords)\n",
    "                dev_predictions.append(s)        \n",
    "\n",
    "    # calc mean of losses\n",
    "    valid_loss /= len(dev_loader)\n",
    "    valid_mask_loss /= len(dev_loader)\n",
    "    valid_regr_loss /= len(dev_loader)\n",
    "\n",
    "    ################ TRY ReduceLROnPlateau\n",
    "    exp_lr_scheduler.step(valid_loss)\n",
    "    \n",
    "    if history is not None:\n",
    "        history.loc[epoch, 'dev_loss'] = valid_loss.cpu().numpy()\n",
    "        history.loc[epoch, 'mask_loss'] = valid_mask_loss.cpu().numpy()\n",
    "        history.loc[epoch, 'regr_loss'] = valid_regr_loss.cpu().numpy()\n",
    "\n",
    "    if True:\n",
    "        CV_dev = pd.DataFrame()\n",
    "        CV_dev[\"ImageId\"] = df_dev.ImageId.copy()\n",
    "        CV_dev['PredictionString'] = dev_predictions\n",
    "        mapval = calc_map(CV_dev)\n",
    "        history.loc[epoch, 'map'] = mapval\n",
    "\n",
    "    print('    DevLoss: {:.4f}\\tMaskLoss: {:.4f}\\tRegLoss: {:.4f}\\tmAP: {:.6f}'.format(\n",
    "            valid_loss, valid_mask_loss, valid_regr_loss, mapval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "nbpresent": {
     "id": "b046b96a-2aed-4ec4-b67d-b4aaed38dcfa"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import gc\n",
    "\n",
    "history = pd.DataFrame()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    train_one(epoch, history)\n",
    "    evaluate(epoch, history)\n",
    "    if epoch >= 10:\n",
    "        torch.save(model.state_dict(), f'./model_epoch_{epoch}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "65a6cefb-eee9-4dcf-a45f-f354ef4f881c"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e7395670-5881-401b-a3d2-e190fa45279d"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history['train_loss'].iloc[100:].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5c180fda-6e38-40aa-a0be-95d251287c23"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "labels = ['train_loss', 'train_mask_loss', \"train_regr_loss\"]\n",
    "tr_logs = history[labels].dropna()\n",
    "losses_arr = [ tr_logs.query(f\"index > {_e} & index < {_e+1}\").mean().values for _e in range(n_epochs)]\n",
    "tr_logs_arr = np.array( losses_arr ).T\n",
    "\n",
    "plt.plot(tr_logs_arr[0],   \"r--\",label=labels[0])\n",
    "plt.plot(tr_logs_arr[1],   \"b--\",label=labels[1])\n",
    "plt.plot(tr_logs_arr[2]*10,\"g--\" ,label=labels[2] +\" *10\")\n",
    "\n",
    "series3 = history.dropna()['dev_loss']\n",
    "series1 = history.dropna()['mask_loss']\n",
    "series2 = history.dropna()['regr_loss']\n",
    "series4 = history.dropna()['map']\n",
    "\n",
    "plt.plot(series3.index, series3   , \"r\", label = 'dev loss');\n",
    "plt.plot(series1.index, series1   , \"b\", label = 'mask loss');\n",
    "plt.plot(series2.index, series2*10, \"g\", label = 'regr loss');\n",
    "\n",
    "plt.plot(series2.index, series4*100,  \"k\", label = 'mAP*100');\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(range(100))\n",
    "plt.yticks(range(100))\n",
    "plt.xlim(0,n_epochs)\n",
    "plt.ylim(0,20)\n",
    "\n",
    "plt.savefig(\"Loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "508883d6-88e4-41e7-84f3-df143f45b1fc"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['train_loss', 'train_mask_loss', \"train_regr_loss\"]\n",
    "tr_logs = history[labels].dropna()\n",
    "losses_arr = [ tr_logs.query(f\"index > {_e} & index < {_e+1}\").mean().values for _e in range(n_epochs)]\n",
    "tr_logs_arr = np.array( losses_arr ).T\n",
    "\n",
    "plt.plot(tr_logs_arr[0], label=labels[0])\n",
    "plt.plot(tr_logs_arr[1], label=labels[1])\n",
    "plt.plot(tr_logs_arr[2] * 10, label=labels[2] +\" *10\")\n",
    "plt.title(\"train losses\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig(\"Loss_Train.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "d07de423-3cb5-47e3-acad-19c03c34e902"
    }
   },
   "outputs": [],
   "source": [
    "series1 = history.dropna()['mask_loss']\n",
    "plt.plot(series1.index, series1 ,label = 'mask loss');\n",
    "series2 = history.dropna()['regr_loss']\n",
    "plt.plot(series2.index, 10*series2,label = 'regr loss');\n",
    "series3 = history.dropna()['dev_loss']\n",
    "plt.plot(series3.index, series3,label = 'dev loss');\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"Loss_Val_all.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "249a55e4-37fb-484f-93b8-32c7a05aba98"
    }
   },
   "outputs": [],
   "source": [
    "series = history.dropna()['dev_loss']\n",
    "history[['dev_loss','mask_loss','regr_loss','map']].dropna().to_csv(\"./dev_loss.csv\")\n",
    "plt.grid(True)\n",
    "plt.scatter(series.index, series);\n",
    "plt.savefig(\"Loss_Val.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "03249129-d95f-453b-9cc0-cd8eabb1135e"
    }
   },
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "nbpresent": {
     "id": "30d6b8b1-062c-4f02-8a71-c5a15c3f947d"
    }
   },
   "outputs": [],
   "source": [
    "img, mask, regr, ign_mask, ign_mask_for_feed = dev_dataset[0]\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Input image')\n",
    "plt.imshow(np.rollaxis(img, 0, 3))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Ground truth mask')\n",
    "plt.grid()\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "\n",
    "if USEMASK:\n",
    "    output = infer_image(img[None], ign_mask_for_feed[None])\n",
    "else:\n",
    "    output = model(torch.tensor(img[None]).to(device))\n",
    "logits = output[0,0].data.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Model predictions (8-neighbor peak), TH=0.3')\n",
    "plt.grid()\n",
    "plt.imshow(postprocess_heatmap( logits, thresh=0.3 ))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Model predictions (8-neighbor peak), TH=0.4')\n",
    "plt.grid()\n",
    "plt.imshow(postprocess_heatmap( logits, thresh=0.4 ))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Model predictions (sigmoid)')\n",
    "plt.grid()\n",
    "plt.imshow(sigmoid(logits))\n",
    "plt.show()\n",
    "\n",
    "#print(logits)\n",
    "#plt.figure(figsize=(16,16))\n",
    "#plt.title('Model predictions (simple) thresholded')\n",
    "#plt.imshow(logits > 0)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "82a10cc7-985d-4de2-81ec-23fd2d8fdc36"
    }
   },
   "outputs": [],
   "source": [
    "## Simple test of probabilities\n",
    "act = torch.nn.Sigmoid()\n",
    "logtens = torch.from_numpy(logits)\n",
    "probs = act(logtens)\n",
    "probs = probs[probs>0.03]\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "088bcd5b-3e0f-459e-b353-daaedcc521b8"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "for idx in range(8):\n",
    "    img, heatmap, regr, ign_mask, ign_mask_for_feed = dev_dataset[idx]\n",
    "    mask = (heatmap >= 1).astype(float)\n",
    "    if False: #debug\n",
    "        print(regr.shape)\n",
    "        print(heatmap.shape)\n",
    "        print( REGR_TARGETS )\n",
    "        print(np.where(heatmap == 1))\n",
    "        print(np.where(regr[-1] > 0))\n",
    "        print(regr[ -1 ][heatmap >= 1] )\n",
    "        raise\n",
    "    \n",
    "    if USEMASK:\n",
    "        output = infer_image(img[None], ign_mask_for_feed[None])\n",
    "        output = output.data.cpu().numpy()\n",
    "    else:\n",
    "        output = model(torch.tensor(img[None]).to(device)).data.cpu().numpy()\n",
    "\n",
    "    coords_pred = extract_coords(output[0], ign_mask)\n",
    "    \n",
    "    perfect_logits = 1000 * ( ( heatmap==1 ).astype(float) - 0.5 )\n",
    "    coords_true = extract_coords(np.concatenate([perfect_logits[None], regr], 0), ign_mask)\n",
    "    \n",
    "    img = imread(train_images_dir.format(df_dev['ImageId'].iloc[idx]))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(30,30))\n",
    "    axes[0].set_title('Ground truth')\n",
    "    axes[0].imshow(visualize(img, coords_true))\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[1].imshow(visualize(img, coords_pred))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f6435f54-40fc-434c-bf32-35e267b6a50a"
    }
   },
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "577fe6f6-a3e9-4820-a11f-d72ced002e72"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "#test_loader = DataLoader(dataset=test_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for img, _, _, ign_masks, ign_mask_for_feed_batch in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        if USEMASK:\n",
    "            output = infer_image(img, ign_mask_for_feed_batch)\n",
    "        else:\n",
    "            output = model(img.to(device))\n",
    "    output = output.data.cpu().numpy()\n",
    "    #for out in output:\n",
    "    for out, ign_mask in zip(output, ign_masks):\n",
    "        coords = extract_coords(out, ign_mask)\n",
    "        s = coords2str(coords)\n",
    "        predictions.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "310d2abf-84ed-4c64-a3af-87d36df396f4"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "test['PredictionString'] = predictions\n",
    "# test.to_csv('predictions.csv', index=False)\n",
    "test.to_csv('predictions.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _th in [ 0.40, 0.41, 0.45 ]:\n",
    "    trim_below_threth(test, _th ).to_csv(f'predictions_threth{_th}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7954c05e-205f-4404-8beb-f80874e26739"
    }
   },
   "source": [
    "## metrics codes are copied code from @its7171 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5f1cc81b-c4a1-40b4-b493-c94e9c13c816"
    }
   },
   "outputs": [],
   "source": [
    "dev_predictions = []\n",
    "\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for img, _, _, ign_masks, ign_mask_for_feed_batch in tqdm(dev_loader):\n",
    "    with torch.no_grad():\n",
    "        if USEMASK:\n",
    "            output = infer_image(img, ign_mask_for_feed_batch)\n",
    "        else:\n",
    "            output = model(img.to(device))\n",
    "    output = output.data.cpu().numpy()\n",
    "    #for out in output:\n",
    "    for out, ign_mask in zip(output, ign_masks):\n",
    "        coords = extract_coords(out, ign_mask)\n",
    "        s = coords2str(coords)\n",
    "        dev_predictions.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f65d3944-70d3-4102-98bf-927356663222"
    }
   },
   "outputs": [],
   "source": [
    "CV_dev = pd.DataFrame()\n",
    "CV_dev[\"ImageId\"] = df_dev.ImageId.copy()\n",
    "CV_dev['PredictionString'] = dev_predictions\n",
    "\n",
    "VAL_PRED_PATH = \"validation_pred.csv\"\n",
    "CV_dev.to_csv(VAL_PRED_PATH, index=False)\n",
    "\n",
    "CV_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "d6769ee2-67d1-43ce-a488-28d9c1fc8a5b"
    }
   },
   "outputs": [],
   "source": [
    "### LOAD VALIDATOIN PREDICTION\n",
    "if False:  #reload\n",
    "    CV_dev = pd.read_csv(VAL_PRED_PATH)\n",
    "    #valid_df = pd.read_csv(\"../input/baiducsv/validatoin_pred.csv\")\n",
    "\n",
    "    CV_dev = valid_df.fillna('')\n",
    "    CV_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###mapval = calc_map(valid_df)\n",
    "mapval = calc_map(CV_dev)\n",
    "\n",
    "print('map:', mapval)\n",
    "\n",
    "# save\n",
    "pd.DataFrame({\"val-mAP\": [mapval]}).to_csv(\"val-mAP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_below_threth(CV_dev, 0.45 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for th in np.arange(0.45, 0.71, 0.05):\n",
    "#for th in np.arange(0.30, 0.55, 0.025):\n",
    "for th in np.arange(0.45, 0.55, 0.01):\n",
    "    mapval = calc_map( trim_below_threth(CV_dev, th) )\n",
    "    print(f'threth:{th} map:{mapval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "010231caa5dc4bf6bf52729318d57dc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "011ef9b36f1647dcb2b79633fe676d5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ad18a6f52434d1e9c04a556dcbf7c01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "12715ee8417c4ee08ab893f82ea326b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "train_loss (l=7.707)(m=8.40) (r=1.4336:  87%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6acad8d4be614c9aa4090c2275936951",
       "max": 2110,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_23a07071dc60406ea3bb996eb5e54876",
       "value": 1844
      }
     },
     "19fd25800b8848d49308a59f00cc62eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ce633dde9ca4c4b896ee3804c0b1495": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e5b845f0fbc34656a8dee792d1374c5c",
        "IPY_MODEL_511b25623b584448b786caa309e605ab"
       ],
       "layout": "IPY_MODEL_d4713eb31fe14b12b2fea829c99b24fc"
      }
     },
     "21ccc09920fa46cbad188db6cfca3620": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "23a07071dc60406ea3bb996eb5e54876": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "2484eaa98b4e4ae98dd2c4f09f6081c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "257830d9d3564b04821fdd1d068c2d6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bf76c7ee5e134736951608701cd620c8",
       "placeholder": "​",
       "style": "IPY_MODEL_fdfef792cc1e4dfda40424426b560e9d",
       "value": " 2110/2110 [31:43&lt;00:00,  1.11it/s]"
      }
     },
     "25eb824ca7fb407198644df594bd9d83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ba407f133f91497f9b10aee46d5a1401",
        "IPY_MODEL_f3395e7328fd4ec080c56b1866f2901f"
       ],
       "layout": "IPY_MODEL_aa2c176f57e14786a2afec0baf176089"
      }
     },
     "314bfc6544894ea6b2bbe581ee724421": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b80cd99bf9a6464fb4f5360c3ffca942",
        "IPY_MODEL_ab648d8b05bc4dce899d11a375b3d484"
       ],
       "layout": "IPY_MODEL_19fd25800b8848d49308a59f00cc62eb"
      }
     },
     "3413a6188ad944998f14dcb763d9cc29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81da305dd7a84cc38dcf4c59f63aa50a",
       "placeholder": "​",
       "style": "IPY_MODEL_b2de4564da6240689e88dffa777ccda7",
       "value": " 506/506 [12:39&lt;00:00,  1.50s/it]"
      }
     },
     "373b1e1349b946eaaed153bf4d4b41cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_12715ee8417c4ee08ab893f82ea326b2",
        "IPY_MODEL_7d444cc91e914cf287bd18d95f9bb610"
       ],
       "layout": "IPY_MODEL_0ad18a6f52434d1e9c04a556dcbf7c01"
      }
     },
     "396a945cfaa14cd3a14101582239914d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4285e3b9c8e94b7db07c168c48b501d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42e27f7780e548489febe4fd5caf9205": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "48701d3555e4455e89227790822541e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d4c77f917734536a8e596f636b51821": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4edef3729d48420f9908f0d5ab36ebb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "501898601c0a4ef8b6148d3862e18f39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "511b25623b584448b786caa309e605ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbc9d3b6c17a4eff81a6fecb83478032",
       "placeholder": "​",
       "style": "IPY_MODEL_edbf9df4464c408ba730a220462fddee",
       "value": " 2110/2110 [31:50&lt;00:00,  1.10it/s]"
      }
     },
     "52e5632763c14ff8ab6f8df60bfff3f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "train_loss (l=8.855)(m=9.63) (r=1.8528: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_010231caa5dc4bf6bf52729318d57dc6",
       "max": 2110,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_501898601c0a4ef8b6148d3862e18f39",
       "value": 2110
      }
     },
     "5aafcbb1cd30456094dc7faa7e07bb92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f311c8e8b8547329588132a438c68cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "5ff1ce3633794141a488700b5baa2c3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "614892bb0c304b859ac44bb563164e67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_52e5632763c14ff8ab6f8df60bfff3f2",
        "IPY_MODEL_257830d9d3564b04821fdd1d068c2d6b"
       ],
       "layout": "IPY_MODEL_2484eaa98b4e4ae98dd2c4f09f6081c0"
      }
     },
     "62e5e6d7cf9d43cdb06c7dcad615870d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a146aeee32b4d3f936c95e59387ee22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "train_loss (l=3.508)(m=5.91) (r=1.1073:  83%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4285e3b9c8e94b7db07c168c48b501d7",
       "max": 2110,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5f311c8e8b8547329588132a438c68cf",
       "value": 1761
      }
     },
     "6acad8d4be614c9aa4090c2275936951": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71a2fd5d1a4547c8b86caa431444955c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ccbf3c3738564021b26c73d9a1708a02",
       "placeholder": "​",
       "style": "IPY_MODEL_21ccc09920fa46cbad188db6cfca3620",
       "value": " 1761/2110 [26:32&lt;05:18,  1.10it/s]"
      }
     },
     "7bb9b4fe7e834dba82913aa5ac870df0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9e5b929cccdb4a4d853e5292a8ad3abd",
        "IPY_MODEL_875a829fb4944b7ebb9243c32432d7e1"
       ],
       "layout": "IPY_MODEL_62e5e6d7cf9d43cdb06c7dcad615870d"
      }
     },
     "7d444cc91e914cf287bd18d95f9bb610": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_48701d3555e4455e89227790822541e7",
       "placeholder": "​",
       "style": "IPY_MODEL_42e27f7780e548489febe4fd5caf9205",
       "value": " 1844/2110 [27:33&lt;03:58,  1.11it/s]"
      }
     },
     "81da305dd7a84cc38dcf4c59f63aa50a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "825568318a4a46c6ab47301ced8826dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "875a829fb4944b7ebb9243c32432d7e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4d4c77f917734536a8e596f636b51821",
       "placeholder": "​",
       "style": "IPY_MODEL_e2f5472f76b84ff391593f68022f7df2",
       "value": " 2110/2110 [32:03&lt;00:00,  1.10it/s]"
      }
     },
     "9e5b929cccdb4a4d853e5292a8ad3abd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "train_loss (l=2.627)(m=4.31) (r=0.9429: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c60d5f87473f41f3bbcc172f2d86c698",
       "max": 2110,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a176842d2eae4d63b1543c68a7599580",
       "value": 2110
      }
     },
     "a176842d2eae4d63b1543c68a7599580": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a84aa257be714016b84221316fed7424": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa2c176f57e14786a2afec0baf176089": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab648d8b05bc4dce899d11a375b3d484": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_396a945cfaa14cd3a14101582239914d",
       "placeholder": "​",
       "style": "IPY_MODEL_cc1e578555044ef3b1e9a3b06a170079",
       "value": " 0/11 [00:08&lt;?, ?it/s]"
      }
     },
     "ac39390ffebb4428b583a19c05ea7747": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ace7f55bd91f4c39abed8e78f43ae6ae",
        "IPY_MODEL_3413a6188ad944998f14dcb763d9cc29"
       ],
       "layout": "IPY_MODEL_facff56c353b412fb50500e37d0db287"
      }
     },
     "ace7f55bd91f4c39abed8e78f43ae6ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_011ef9b36f1647dcb2b79633fe676d5a",
       "max": 506,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d064543263d34971b0d823cee7bc5a82",
       "value": 506
      }
     },
     "b2de4564da6240689e88dffa777ccda7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b80cd99bf9a6464fb4f5360c3ffca942": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  0%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5ff1ce3633794141a488700b5baa2c3f",
       "max": 11,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d3a4d8b8e3bb48e8b0da4d95121663c3",
       "value": 0
      }
     },
     "ba407f133f91497f9b10aee46d5a1401": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  0%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d787c2260ed442ae83e9807f6e30826e",
       "max": 2110,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_825568318a4a46c6ab47301ced8826dd",
       "value": 1
      }
     },
     "bbc9d3b6c17a4eff81a6fecb83478032": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf76c7ee5e134736951608701cd620c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c60d5f87473f41f3bbcc172f2d86c698": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc1e578555044ef3b1e9a3b06a170079": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ccbf3c3738564021b26c73d9a1708a02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d064543263d34971b0d823cee7bc5a82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d3a4d8b8e3bb48e8b0da4d95121663c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d4713eb31fe14b12b2fea829c99b24fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d787c2260ed442ae83e9807f6e30826e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e15fd97a84484224a73235399db0d8e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e2f5472f76b84ff391593f68022f7df2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e5b845f0fbc34656a8dee792d1374c5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "train_loss (l=5.166)(m=5.58) (r=1.4540: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a84aa257be714016b84221316fed7424",
       "max": 2110,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e15fd97a84484224a73235399db0d8e2",
       "value": 2110
      }
     },
     "edbf9df4464c408ba730a220462fddee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f129206f4fad4775b75e504be84eca38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3395e7328fd4ec080c56b1866f2901f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5aafcbb1cd30456094dc7faa7e07bb92",
       "placeholder": "​",
       "style": "IPY_MODEL_4edef3729d48420f9908f0d5ab36ebb9",
       "value": " 1/2110 [00:05&lt;3:20:02,  5.69s/it]"
      }
     },
     "f43bf8dd5b4d40ae99a12205ef822cbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6a146aeee32b4d3f936c95e59387ee22",
        "IPY_MODEL_71a2fd5d1a4547c8b86caa431444955c"
       ],
       "layout": "IPY_MODEL_f129206f4fad4775b75e504be84eca38"
      }
     },
     "facff56c353b412fb50500e37d0db287": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdfef792cc1e4dfda40424426b560e9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
